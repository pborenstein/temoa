---
gleaned: 2025-11-15
url: https://news.ycombinator.com/item?id=38309611
tags: [gleaning, rag, privacy]
source: "[[2025-11-15-Fr]]"
---

# Building a Local RAG System

HN discussion on local vs cloud RAG systems. Privacy considerations are a real concern for people.

Key points:
- Cloud RAG (OpenAI, Anthropic): Convenient but data leaves your machine
- Local RAG (Ollama, llama.cpp): Privacy but requires decent hardware
- Hybrid: Local embeddings, cloud LLM (best of both worlds?)

For personal knowledge, local embeddings seem like the right trade-off. Can always add cloud LLM later.

[Link](https://news.ycombinator.com/item?id=38309611)
